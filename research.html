<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sabrine Amri - Research</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <nav class="navbar">
            <ul>
                <li><a href="index.html" id="nav-profile" class="nav-link">Profile</a></li>
                <li><a href="research.html" id="nav-research" class="nav-link">Research</a></li>
                <li><a href="publications.html" id="nav-publications" class="nav-link">Publications</a></li>
                <li><a href="teaching.html" id="nav-teaching" class="nav-link">Teaching</a></li>
                <li><a href="co_supervision.html" id="nav-co-supervision" class="nav-link">Co-supervised Students</a></li>
            </ul>
            <div class="language-switcher">
                <select id="language-select">
                    <option value="en">English</option>
                    <option value="fr">Français</option>
                </select>
            </div>
        </nav>
    </header>

    <main>
        <!-- English content -->
        <section class="profile-section" id="content-en">
            <h1>Research Overview</h1>
            <!-- Add description here -->
            <p>This page presents my academic research, including my past and ongoing projects in the fields of artificial intelligence, cybersecurity, machine learning, and virtual machine placement in cloud computing environments. You will also find details on my current research interrest related to the use of large language models (LLMs) and their privacy risks.</p>
    
            
            <h2>Ph.D. Research: Multiagent Approach for Detecting and Mitigating False Information</h2>
            <p>In my Ph.D., I explored a critical issue in cybersecurity. Detecting and mitigating the spread of false information, including fake news, misinformation, and disinformation on online social networks. False information poses a significant threat to cybersecurity, as it manipulates public perception and leads to widespread societal and political disruption.</p>
            <p>My research introduced a multiagent system that integrates <strong>natural language processing (NLP)</strong> and <strong>machine learning</strong> tasks to detect false information in online platforms. The approach focused on:</p>
            <ul>
                <li><strong>Multimodal Content Analysis</strong>: Analyzing various forms of content, such as text and images to identify potential indicators of false information.</li>
                <li><strong>Contextual Analysis</strong>: Considering the context in which information is shared, including surrounding data to better understand the credibility of the information.</li>
                <li><strong>External Evidence and Web Scraping</strong>: Cross-referencing content with trusted external sources, such as official websites and fact-checkers, to verify its accuracy using advanced web scraping techniques.</li>
                <li><strong>Explainable AI</strong>: Emphasizing the importance of transparency in AI decisions, I used <strong>Explainable AI</strong> methods to provide interpretable results that help users understand why specific information is flagged as false.</li>
            </ul>

            <h2>Current Research Interests: Large Language Models (LLMs) and Privacy Risks</h2>
            <p>As the field of artificial intelligence evolves, I am currently focusing my research on the applications and risks associated with <strong>Large Language Models (LLMs)</strong>. LLMs, like GPT and BERT, have shown impressive capabilities in generating human-like text and understanding complex language patterns. However, they also introduce significant <strong>privacy risks</strong>, particularly in scenarios where sensitive user data might be exposed or exploited.</p>
            <p>My ongoing research investigates the privacy challenges posed by LLMs, with a focus on safeguarding user information and developing techniques to mitigate potential data leaks. Additionally, I am exploring the ethical implications of deploying LLMs in sensitive environments, ensuring that AI applications remain secure and trustworthy.</p>
            
            <h2>Master's Research: Virtual Machine Consolidation and Cloud Performance</h2>
            <p>During my master's studies, my research focused on addressing performance interference issues and optimizing virtual machine consolidation in cloud computing environments. In large-scale cloud infrastructures, multiple virtual machines (VMs) can experience performance degradation due to resource contention. My work involved designing solutions that manage these performance interferences effectively, ensuring a balanced allocation of resources.</p>

        </section>

        <!-- French content -->
        <section class="profile-section" id="content-fr" style="display: none;">
            <h1>Vue d'ensemble de la recherche</h1>
            <!-- Add description in French here -->
            <p>Cette page présente mes recherches académiques, y compris mes projets passés et en cours dans les domaines de l'intelligence artificielle, de la cybersécurité, de l'apprentissage automatique, et du placement des machines virtuelles dans les environnements cloud computing. Vous y trouverez également des détails sur mes interrets de recherches actuelles liées à l'usage des grands modèles de langage (LLM) et à leurs risques en matière de confidentialité.</p>
    

           
            <h2>Recherche de doctorat : Approche multiagent pour la détection et l'atténuation des fausses informations</h2>
            <p>Dans le cadre de mon doctorat, j'ai exploré une problématique critique en cybersécurité : la détection et l'atténuation de la propagation des fausses informations, y compris les fausses nouvelles, la désinformation et la mésinformation sur les réseaux sociaux en ligne. Les fausses informations représentent une menace importante pour la cybersécurité, car elles manipulent la perception publique et conduisent à des perturbations sociétales et politiques de grande envergure.</p>
            <p>Mes recherches ont introduit un système multiagent intégrant le <strong>traitement du langage naturel (NLP)</strong> et <strong>l'apprentissage automatique</strong> pour détecter les fausses informations sur les plateformes en ligne. L'approche se concentrait sur :</p>
            <ul>
                <li><strong>Analyse multimodale du contenu</strong> : Analyse de diverses formes de contenu, telles que le texte et les images pour identifier les indicateurs potentiels de fausses informations.</li>
                <li><strong>Analyse contextuelle</strong> : Considération du contexte dans lequel les informations sont partagées, y compris les données environnantes afin de mieux comprendre la crédibilité des informations.</li>
                <li><strong>Évidence externe et scraping web</strong> : Recouper le contenu avec des sources externes fiables, telles que des sites officiels et des vérificateurs de faits, pour en vérifier l'exactitude en utilisant des techniques avancées de scraping web.</li>
                <li><strong>IA explicable</strong> : En mettant l'accent sur l'importance de la transparence dans les décisions de l'IA, j'ai utilisé des méthodes d'<strong>IA explicable</strong> pour fournir des résultats interprétables qui aident les utilisateurs à comprendre pourquoi certaines informations sont signalées comme fausses.</li>
            </ul>

            <h2>Intérêts de recherche actuels : Modèles de langage de grande taille (LLMs) et risques de confidentialité</h2>
            <p>À mesure que le domaine de l'intelligence artificielle évolue, je concentre actuellement mes recherches sur les applications et les risques associés aux <strong>Modèles de langage de grande taille (LLMs)</strong>. Les LLM, tels que GPT et BERT, ont montré des capacités impressionnantes à générer du texte ressemblant à celui des humains et à comprendre des modèles linguistiques complexes. Cependant, ils introduisent également des <strong>risques de confidentialité</strong> significatifs, en particulier dans les scénarios où des données utilisateur sensibles pourraient être exposées ou exploitées.</p>
            <p>Mes recherches en cours examinent les défis en matière de confidentialité posés par les LLM, en se concentrant sur la protection des informations des utilisateurs et sur le développement de techniques pour atténuer les fuites potentielles de données. De plus, j'explore les implications éthiques du déploiement des LLM dans des environnements sensibles, en veillant à ce que les applications d'IA restent sécurisées et dignes de confiance.</p>
        
            <h2>Recherche de master : Consolidation des machines virtuelles et performance dans le cloud</h2>
            <p>Pendant mes études de master, mes recherches se sont concentrées sur la gestion des interférences de performance et l'optimisation de la consolidation des machines virtuelles dans les environnements de cloud computing. Dans les infrastructures cloud à grande échelle, plusieurs machines virtuelles (VM) peuvent subir une dégradation des performances en raison de la concurrence des ressources. Mon travail a consisté à concevoir des solutions qui gèrent efficacement ces interférences, assurant ainsi une allocation équilibrée des ressources.</p>

        </section>
    </main>

    <footer>
        <p>&copy; 2024 Sabrine Amri</p>
    </footer>

    <script src="script.js"></script>
</body>
</html>
